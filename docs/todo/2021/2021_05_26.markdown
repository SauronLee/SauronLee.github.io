---
layout: default
title: May 26
parent: 2021
grand_parent: Progress Report
---

```txt

05/26 進捗報告　Xiaoran Li

[研究テーマ]
多言語融合による教師なし意義素学習

[現在の目標]
現在の目標は、クラスタリング効果に対する前処理の影響を分析することです。 そして、最適な前処理を選択します。

[今週の実施内容]
(5/19) 水曜日 ： BPE（Byte Pair Encoding）BaseでWikipediaの日本語コーパスを使って32000詞、56000詞、80000詞をサブワード分割しました
(5/20) 木曜日 ： そして中国語を同じ方法を使って32000詞、56000詞、80000詞をサブワード分割しました
(5/21) 金曜日 ： Glove（Global Vectors）Baseで以上の単語を32000詞の場合300次元、56000詞、80000詞の場合768次元を訓練しました。（300次元の場合5時間がかかる、768次元の場合10時間がかかる）
(5/22) 土曜日 ： Training。。。
(5/23) 日曜日 ： Training。。。
(5/24) 月曜日 ： Training。。。
(5/25) 火曜日 ： 出張した

[今回の実績]
(1) 順調に進んていました。

(2) 教師なし機械翻訳、多言語の共通の語義学習に対して、BPE(サブワード分割) + Fastext(単語埋め込み)のほうが良い表現を出ました（ただ英語語族の表現が良い）、もちろん自分もBPE＋Fasttext方法で訓練するけど、意義素が新しい領域から多様な手法で比べて論文を作成しる。（現在最優な教師なし機械翻訳モデルはBPEが80000詞をサブワード分割ですけど、しかし、中国語や日本語のような言語は、より良い結果を得るために、サブワード数が多いほど良い。）

(3) 意義素空間学習の部分が計算手法を変換した（全部GPUで行列乗算の形でした、速度は以前の10倍以上になった）。

[参考文献]
特に無い

[次回の目標]
意義素空間（クラスタリング後の中国語と日本語の意味空間）の類似性を比較します。そして判断して他の国の言語を加入する必要性。
比較方法はこの論文「Word Translation without Parallel Data」を使います

```